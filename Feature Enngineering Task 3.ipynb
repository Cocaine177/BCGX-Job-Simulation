{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8f6b25a-93a8-4766-99de-ac3eb8e16c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (14606, 44)\n",
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14606 entries, 0 to 14605\n",
      "Data columns (total 44 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              14606 non-null  object \n",
      " 1   channel_sales                   14606 non-null  object \n",
      " 2   cons_12m                        14606 non-null  int64  \n",
      " 3   cons_gas_12m                    14606 non-null  int64  \n",
      " 4   cons_last_month                 14606 non-null  int64  \n",
      " 5   date_activ                      14606 non-null  object \n",
      " 6   date_end                        14606 non-null  object \n",
      " 7   date_modif_prod                 14606 non-null  object \n",
      " 8   date_renewal                    14606 non-null  object \n",
      " 9   forecast_cons_12m               14606 non-null  float64\n",
      " 10  forecast_cons_year              14606 non-null  int64  \n",
      " 11  forecast_discount_energy        14606 non-null  float64\n",
      " 12  forecast_meter_rent_12m         14606 non-null  float64\n",
      " 13  forecast_price_energy_off_peak  14606 non-null  float64\n",
      " 14  forecast_price_energy_peak      14606 non-null  float64\n",
      " 15  forecast_price_pow_off_peak     14606 non-null  float64\n",
      " 16  has_gas                         14606 non-null  object \n",
      " 17  imp_cons                        14606 non-null  float64\n",
      " 18  margin_gross_pow_ele            14606 non-null  float64\n",
      " 19  margin_net_pow_ele              14606 non-null  float64\n",
      " 20  nb_prod_act                     14606 non-null  int64  \n",
      " 21  net_margin                      14606 non-null  float64\n",
      " 22  num_years_antig                 14606 non-null  int64  \n",
      " 23  origin_up                       14606 non-null  object \n",
      " 24  pow_max                         14606 non-null  float64\n",
      " 25  var_year_price_off_peak_var     14606 non-null  float64\n",
      " 26  var_year_price_peak_var         14606 non-null  float64\n",
      " 27  var_year_price_mid_peak_var     14606 non-null  float64\n",
      " 28  var_year_price_off_peak_fix     14606 non-null  float64\n",
      " 29  var_year_price_peak_fix         14606 non-null  float64\n",
      " 30  var_year_price_mid_peak_fix     14606 non-null  float64\n",
      " 31  var_year_price_off_peak         14606 non-null  float64\n",
      " 32  var_year_price_peak             14606 non-null  float64\n",
      " 33  var_year_price_mid_peak         14606 non-null  float64\n",
      " 34  var_6m_price_off_peak_var       14606 non-null  float64\n",
      " 35  var_6m_price_peak_var           14606 non-null  float64\n",
      " 36  var_6m_price_mid_peak_var       14606 non-null  float64\n",
      " 37  var_6m_price_off_peak_fix       14606 non-null  float64\n",
      " 38  var_6m_price_peak_fix           14606 non-null  float64\n",
      " 39  var_6m_price_mid_peak_fix       14606 non-null  float64\n",
      " 40  var_6m_price_off_peak           14606 non-null  float64\n",
      " 41  var_6m_price_peak               14606 non-null  float64\n",
      " 42  var_6m_price_mid_peak           14606 non-null  float64\n",
      " 43  churn                           14606 non-null  int64  \n",
      "dtypes: float64(29), int64(7), object(8)\n",
      "memory usage: 4.9+ MB\n",
      "None\n",
      "\n",
      "--- Column Names ---\n",
      "Index(['channel_sales', 'cons_12m', 'cons_gas_12m', 'cons_last_month',\n",
      "       'date_activ', 'date_modif_prod', 'date_renewal', 'forecast_cons_12m',\n",
      "       'forecast_cons_year', 'forecast_discount_energy',\n",
      "       'forecast_meter_rent_12m', 'forecast_price_energy_off_peak',\n",
      "       'forecast_price_energy_peak', 'forecast_price_pow_off_peak', 'has_gas',\n",
      "       'imp_cons', 'margin_gross_pow_ele', 'margin_net_pow_ele', 'nb_prod_act',\n",
      "       'net_margin', 'num_years_antig', 'origin_up', 'pow_max',\n",
      "       'var_year_price_off_peak_var', 'var_year_price_peak_var',\n",
      "       'var_year_price_mid_peak_var', 'var_year_price_off_peak_fix',\n",
      "       'var_year_price_peak_fix', 'var_year_price_mid_peak_fix',\n",
      "       'var_year_price_off_peak', 'var_year_price_peak',\n",
      "       'var_year_price_mid_peak', 'var_6m_price_off_peak_var',\n",
      "       'var_6m_price_peak_var', 'var_6m_price_mid_peak_var',\n",
      "       'var_6m_price_off_peak_fix', 'var_6m_price_peak_fix',\n",
      "       'var_6m_price_mid_peak_fix', 'var_6m_price_off_peak',\n",
      "       'var_6m_price_peak', 'var_6m_price_mid_peak', 'churn', 'modif_month',\n",
      "       'modif_year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'price_off_peak_var.Dec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price_off_peak_var.Dec'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(clean_data_df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Use correct column names from your dataset\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# If your dataset has: 'price_off_peak_var.Dec' and 'price_off_peak_var.Jan'\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m clean_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_diff_offpeak\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clean_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_off_peak_var.Dec\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m clean_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_off_peak_var.Jan\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# âœ… Step 7: Feature â€“ Average Peak Price (Combining Dec & Jan)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m clean_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_price_peak\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (clean_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_peak_var.Dec\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m clean_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_peak_var.Jan\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price_off_peak_var.Dec'"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Step 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# âœ… Step 2: Load Cleaned Dataset\n",
    "clean_data_df = pd.read_csv(\"clean_data_after_eda.csv\")\n",
    "\n",
    "# âœ… Step 3: Initial Check â€“ Shape & Info\n",
    "print(\"Data Shape:\", clean_data_df.shape)\n",
    "print(\"\\n--- Data Info ---\")\n",
    "print(clean_data_df.info())\n",
    "\n",
    "# âœ… Step 4: Remove Unnecessary Columns\n",
    "# Columns with only 1 unique value or irrelevant to prediction\n",
    "cols_to_drop = ['id', 'date_end']  # Change this list based on actual dataset\n",
    "clean_data_df.drop(columns=cols_to_drop, inplace=True, errors='ignore')  # avoid error if column not found\n",
    "\n",
    "# âœ… Step 5: Handle Dates â€“ Convert and Extract Features\n",
    "# Convert date to datetime format\n",
    "clean_data_df['date_modif_prod'] = pd.to_datetime(clean_data_df['date_modif_prod'], errors='coerce')\n",
    "\n",
    "# Extract useful date parts (Feature Expansion)\n",
    "clean_data_df['modif_month'] = clean_data_df['date_modif_prod'].dt.month\n",
    "clean_data_df['modif_year'] = clean_data_df['date_modif_prod'].dt.year\n",
    "\n",
    "# âœ… Step 6: Feature â€“ Price Sensitivity (Off-Peak December vs January)\n",
    "# Check actual column names first!\n",
    "print(\"\\n--- Column Names ---\")\n",
    "print(clean_data_df.columns)\n",
    "\n",
    "# Use correct column names from your dataset\n",
    "# If your dataset has: 'price_off_peak_var.Dec' and 'price_off_peak_var.Jan'\n",
    "clean_data_df['price_diff_offpeak'] = clean_data_df['price_off_peak_var.Dec'] - clean_data_df['price_off_peak_var.Jan']\n",
    "\n",
    "# âœ… Step 7: Feature â€“ Average Peak Price (Combining Dec & Jan)\n",
    "clean_data_df['avg_price_peak'] = (clean_data_df['price_peak_var.Dec'] + clean_data_df['price_peak_var.Jan']) / 2\n",
    "\n",
    "# âœ… Step 8: Optional â€“ Combine Usage & Margin to Create Profit Feature\n",
    "clean_data_df['est_profit'] = clean_data_df['cons_12m'] * clean_data_df['net_margin']\n",
    "\n",
    "# âœ… Step 9: Final Check â€“ Head & Summary\n",
    "print(\"\\n--- Final Data Preview ---\")\n",
    "print(clean_data_df.head())\n",
    "\n",
    "print(\"\\n--- Final Columns ---\")\n",
    "print(clean_data_df.columns)\n",
    "\n",
    "# âœ… Step 10: Save Updated Dataset\n",
    "clean_data_df.to_csv(\"feature_engineered_data.csv\", index=False)\n",
    "print(\"\\nâœ… Feature engineered data saved as 'feature_engineered_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e687ff3-68c6-41dd-bd0d-dbd05f35654f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
